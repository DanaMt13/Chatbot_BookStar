# chatbot.py â€” RAG strict: titlul final = top-1 din vector store

from typing import Optional, List, Tuple
import json
from openai import OpenAI

from config import CHAT_MODEL, OPENAI_API_KEY, MODERATION_ENABLED
from rag.retriever import auto_search_books, semantic_search   # <-- avem È™i snippete
from tools.summary_tool import TOOL_SPEC, get_summary_by_title
from safety.moderation import moderate_text, explain_categories

client = OpenAI(api_key=OPENAI_API_KEY)

FALLBACK_BAD_WORDS = {
    "nigger","nigga","hitler","nazist","nazi","jidan","È›igan","tigan",
    "hate","urÄƒ","fuck","shit","idiot","prost","imbecil","handicapat"
}

# praguri doar pentru mesaje de â€œÃ®ncredereâ€, nu influenÈ›eazÄƒ alegerea (care e strict top-1)
MAX_SHOW_ITEMS = 5

def _fallback_blocklist(text: str) -> bool:
    t = (text or "").lower()
    return any(w in t for w in FALLBACK_BAD_WORDS)

def _blocked_message(reason: str) -> str:
    return (
        "AÈ™ vrea sÄƒ pÄƒstrÄƒm conversaÈ›ia respectuoasÄƒ È™i sigurÄƒ. "
        f"Mesajul tÄƒu pare sÄƒ Ã®ncalce regulile de conÈ›inut ({reason}).\n\n"
        "Te rog reformuleazÄƒ fÄƒrÄƒ termeni de urÄƒ, violenÈ›Äƒ, hÄƒrÈ›uire sau conÈ›inut sexual explicit, "
        "iar eu te ajut imediat. =)"
    )

def _format_topk_section(pairs: List[Tuple[str, float]], k_selected: Optional[int] = None) -> str:
    if not pairs:
        return ""
    if k_selected is None:
        k_selected = min(len(pairs), MAX_SHOW_ITEMS)
    lines = []
    for i, (title, dist) in enumerate(pairs[:k_selected], 1):
        try:
            d = float(dist)
            sim = 1.0 - d
        except Exception:
            d = dist
            sim = 0.0
        lines.append(f"{i}. **{title}** Â· dist: `{d:.4f}` Â· sim: `{sim:.4f}`")
    return "\n\n---\nğŸ” Top potriviri (RAG)\n" + "\n".join(lines)

def _extract_pairs(auto_obj) -> List[Tuple[str, float]]:
    # acceptÄƒ forme variate din retriever
    if not isinstance(auto_obj, dict):
        return []
    pairs = auto_obj.get("candidates") or []
    out = []
    for it in pairs:
        if isinstance(it, (list, tuple)) and len(it) >= 2:
            out.append((str(it[0]), float(it[1])))
        elif isinstance(it, dict) and "title" in it and "distance" in it:
            out.append((str(it["title"]), float(it["distance"])))
    return out

def chat(user_query: str, collection) -> str:
    # 0) Moderation
    if MODERATION_ENABLED:
        mod = moderate_text(user_query)
        if mod.get("flagged"):
            reason = explain_categories(mod.get("categories", {})) or "conÈ›inut interzis"
            return _blocked_message(reason)
        if mod.get("error") and _fallback_blocklist(user_query):
            return _blocked_message("conÈ›inut interzis (fallback local)")
    else:
        if _fallback_blocklist(user_query):
            return _blocked_message("conÈ›inut interzis")

    # 1) RAG: obÈ›ine Top-K È™i alege STRICT top-1
    auto = auto_search_books(user_query, collection) or {}
    pairs = _extract_pairs(auto)
    if not pairs:
        # fÄƒrÄƒ potriviri: rÄƒspuns bland
        return "Nu am gÄƒsit o potrivire relevantÄƒ Ã®n biblioteca curentÄƒ. ÃncearcÄƒ sÄƒ formulezi altfel interesul (ex.: teme, gen, ton)."

    # top-1 (titlu + distanÈ›Äƒ)
    best_title, best_dist = pairs[0]
    topk_section = _format_topk_section(pairs, k_selected=min(len(pairs), MAX_SHOW_ITEMS))

    # snippete pentru titlul ales (arÄƒtÄƒm de ce Ã®l propunem)
    evidence_snip = ""
    try:
        ev = semantic_search(user_query, collection, top_k=MAX_SHOW_ITEMS)
        for e in ev:
            if (e.get("title") or "").strip().lower() == best_title.strip().lower():
                evidence_snip = e.get("snippet", "")
                break
    except Exception:
        pass

    # 2) ForÈ›Äƒm tool calling pentru titlul ales (LLM NU mai poate alege altceva)
    system_msg = {
        "role": "system",
        "content": (
            "EÈ™ti Smart Librarian. Titlul final a fost ales de sistem pe baza RAG È™i este FIXAT.\n"
            "TREBUIE sÄƒ apelezi funcÈ›ia get_summary_by_title cu EXACT acest titlu, apoi vei genera rÄƒspunsul final.\n"
            "Nu inventa titluri È™i nu schimba titlul decis."
        )
    }
    chosen_msg = {"role": "system", "content": f"CHOSEN_TITLE={best_title}"}
    user_msg   = {"role": "user", "content": (user_query or "").strip()}

    # forÈ›Äƒm tool-ul explicit
    first = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[system_msg, chosen_msg, user_msg],
        tools=TOOL_SPEC,
        tool_choice={"type": "function", "function": {"name": "get_summary_by_title"}},
    )
    assistant_msg = first.choices[0].message

    # 3) ExecutÄƒm tool-ul (cu titlul fixat)
    summary_text = get_summary_by_title(best_title)

    # 4) Al doilea apel â€” cere modelului sÄƒ redacteze folosind rezumatul primit
    messages = [
        system_msg,
        chosen_msg,
        user_msg,
        {
            "role": "assistant",
            "tool_calls": assistant_msg.tool_calls,
            "content": assistant_msg.content or ""
        },
        {
            "role": "tool",
            "tool_call_id": assistant_msg.tool_calls[0].id if assistant_msg.tool_calls else "tool_call_id",
            "name": "get_summary_by_title",
            "content": summary_text
        },
        {
            "role": "system",
            "content": (
                "FormateazÄƒ rÄƒspunsul astfel:\n"
                f"1) RecomandÄƒ **{best_title}** Ã®n 4â€“6 fraze (conversaÈ›ional).\n"
                "2) Apoi o secÈ›iune â€ğŸ“– Rezumat detaliat:â€ cu exact textul primit de la tool.\n"
                "3) O secÈ›iune â€ğŸ” Dovezi RAG (cÄƒutare semanticÄƒ):â€ cu 1â€“2 fraze, folosind snippetul oferit mai jos.\n"
                "Nu adÄƒuga altÄƒ carte."
            )
        },
        {"role": "system", "content": f"RAG_SNIPPET={evidence_snip or ''}"}
    ]
    final = client.chat.completions.create(model=CHAT_MODEL, messages=messages)
    text = final.choices[0].message.content or ""

    # 5) AtaÈ™Äƒm Top-K folosit
    return f"{text}{topk_section}"
